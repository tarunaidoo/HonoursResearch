This repository is for the sole purposes of storing and maintaining my research for Honours project (2025). The main topic is "Formulating plans with LLMs." This research compares classical planning algorithms against LLMs (GPT_models) in order to gain insights into whether or not these models can solely be trusted to form plans of action for more complex real-world tasks. This focused on a 2D-maze implementation environment for the evaluation of the research.

Large Language Models (LLMs)—specifically Generative Pre-Trained Transformer (GPT) models—are widely accessible and are being increasingly considered for complex symbolic tasks. This research evaluates their planning capabilities in 2D maze navigation. A deterministic environment that allows for direct comparison with classical search algorithms such as Breadth-First Search and A* Search. Although traditional methods possess formal correctness guaranties, LLMs inherently lack such guaranties. The study benchmarks LLMs across mazes of varied size and complexity, assessing their ability to generate valid-goal-reaching path plans. This quantitatively evaluates the impact of advanced prompt engineering strategies—including chain-of-thought, verifier-based filtering and tree-of-thought reasoning—on planning successes. Performance is measured using key metrics: success rate, path optimality and computation time. The results provide a grounded assessment of LLM performance in goal-directed planning within structured environments. Thus offering crucial insight into their potential as reasoning agents for future, complex decision-making systems.

The rapid evolution of Large Language Models (LLMs), including architectures such as Generative Pre-trained Transformer (GPT-4), Claude and LLaMA, signifies a fundamental shift in the capacity of artificial intelligence (AI) systems for language interpretation and generation. While LLMs have demonstrated efficacy in traditional Natural Language Processing (NLP) applications — including summarisation, translation and question answering — recent investigations have begun into their potential for executing high-level cognitive functions - specifically planning.

Classical planning in AI requires the derivation of a precise sequence of actions to achieve a pre-defined goal state. This has traditionally operated as a distinct field, complete with its own established formalisms, algorithms and rigorous evaluation metrics. This research focuses on an interpretable and well-bounded instance of planning: 2D maze navigation.

By defining planning as \textit{"the challenge of identifying a valid and efficient path between a start and a goal state"}, a tangible domain is established where both classical search algorithms and LLM-based methodologies can be applied and contrasted. This approach yields a controlled, measurable and scalable environment - well-suited for exploring the emerging goal-directed reasoning abilities of LLMs

This study aims to compare the outputs of established classical search algorithms, such as Breadth-First Search (BFS) and A*, against those produced by LLMs. These are evaluated across maze sizes and structural complexities. A particular emphasis is placed on determining whether LLM performance scales with model size and whether specific complexity thresholds reveal fundamental limitations inherent to language-based planning. The findings have significant implications for the deployment of LLMs within practical decision-making pipelines for domains such as robotics, game AI and simulation-based agents. Particularly in scenarios where conventional symbolic planning is computationally prohibitive or excessively rigid.
